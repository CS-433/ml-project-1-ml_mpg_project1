{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from utilities import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "N = len(y) # training set cardinality\n",
    "D = tX.shape[1] # number of parameters (\"dimensionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data\n",
    "\n",
    "We perform three operations aimed at applying our models on a suitable training dataset.\n",
    "\n",
    "1) Several observations are incomplete, as it can be shown looking at the number of \"-999\"s in the dataset. \n",
    "    To solve this issue, we can eliminate columns where too many data, say 70%, are missing, and we can impose the mean in the remaining cases.\n",
    "\n",
    "2) The values of the features are quite high and spread, so it is a better practice to normalize or standardize the data before proceeding with the implementations. Indeed, GD is very sensitive to ill-conditioning. The two above mentioned methods consist respecively in dividing each feature column by its maximum or by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "3) Outliers should be detected and eliminated from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580052\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(tX==-999)) # counting the missing data in tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.38470000e+02  5.16550000e+01  9.78270000e+01 ...  2.15000000e+00\n",
      "   4.44000000e-01  1.13497000e+02]\n",
      " [ 1.60937000e+02  6.87680000e+01  1.03235000e+02 ...  7.25000000e-01\n",
      "   1.15800000e+00  4.62260000e+01]\n",
      " [ 1.21858528e+02  1.62172000e+02  1.25953000e+02 ...  2.05300000e+00\n",
      "  -2.02800000e+00  4.42510000e+01]\n",
      " ...\n",
      " [ 1.05457000e+02  6.05260000e+01  7.58390000e+01 ...  1.80000000e+00\n",
      "  -1.66000000e-01  4.19920000e+01]\n",
      " [ 9.49510000e+01  1.93620000e+01  6.88120000e+01 ... -3.27458741e-03\n",
      "  -1.23928255e-02  0.00000000e+00]\n",
      " [ 1.21858528e+02  7.27560000e+01  7.08310000e+01 ... -3.27458741e-03\n",
      "  -1.23928255e-02  0.00000000e+00]]\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "tX, D = missing_values(tX)\n",
    "print(tX)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tX = normalize(tX)\n",
    "tX = standardize_tX(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.14910656e-01  6.83319669e-02  4.07680272e-01 ...  1.55729751e+00\n",
      "   3.24824359e-01  4.12510497e-01]\n",
      " [ 7.40827026e-01  5.52504823e-01  5.40136414e-01 ...  5.26704866e-01\n",
      "   8.32993155e-01 -2.73819964e-01]\n",
      " [-5.38802302e-16  3.19515553e+00  1.09655998e+00 ...  1.48714489e+00\n",
      "  -1.43454996e+00 -2.93969845e-01]\n",
      " ...\n",
      " [-3.10930673e-01  3.19316447e-01 -1.30863670e-01 ...  1.30416949e+00\n",
      "  -1.09325452e-01 -3.17017229e-01]\n",
      " [-5.10097335e-01 -8.45323970e-01 -3.02973380e-01 ...  1.00367341e-17\n",
      "   1.11117522e-17 -7.45439413e-01]\n",
      " [-5.38802302e-16  6.65336083e-01 -2.53522760e-01 ...  1.00367341e-17\n",
      "   1.11117522e-17 -7.45439413e-01]]\n",
      "(250000, 23)\n"
     ]
    }
   ],
   "source": [
    "print(tX)\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1 # quantile of order 0.1; this means that we will cut the upper and lower 10% tail\n",
    "tX = eliminate_outliers(tX, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models \n",
    "\n",
    "Application of the 6 models expected for the project, on the prepocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression using Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 500\n",
    "gamma = 0.1\n",
    "initial_w = np.zeros([D,])\n",
    "w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.11017176e-01 -3.56174301e-01 -2.35900974e-01  9.81773887e-02\n",
      "  1.67047733e-01 -2.14679694e-02 -3.85294140e-01  2.38519776e-01\n",
      "  6.41506572e-02  6.49097262e-01 -2.47293775e-03 -1.84308335e-03\n",
      " -2.28074027e-02  4.72584913e-04  3.14827387e-03  3.22785857e-02\n",
      " -2.34555689e-04 -1.30268016e-01  3.17139654e-01  3.07209691e-01\n",
      " -1.44275634e-03 -1.62969347e-03  8.93457870e-03]\n",
      "0.36033025514467687\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 500\n",
    "gamma = 0.01\n",
    "batch_size = 1\n",
    "initial_w = np.zeros([D,])\n",
    "w, loss = least_squares_SGD(y, tX, initial_w, max_iters, gamma, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18440222 -0.25602842  0.06793253  0.17296854  0.12919834 -0.0900654\n",
      " -0.02639086 -0.01308734  0.18318065  0.20851757  0.03951859 -0.13360193\n",
      "  0.04693863  0.00469096 -0.04423778  0.05663676 -0.01453888 -0.00357058\n",
      "  0.07071319  0.03582717 -0.08705132  0.09015691  0.01803553]\n",
      "0.4077851354589864\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares Regression using Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y, tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.46918728e-01 -3.42163482e-01 -3.03194178e-01  1.16321666e-01\n",
      "  1.90076462e-01 -2.98023804e-02 -1.07793902e+00  3.35966742e-01\n",
      "  5.58275403e-02  8.76704721e-01 -2.52186900e-03 -1.69497187e-03\n",
      "  3.86836340e-02  6.00150871e-04  3.26193782e-03  4.72281995e-03\n",
      " -9.16840773e-05 -8.47368490e-02  3.69370475e-01  3.46785042e-01\n",
      " -1.38464372e-03 -1.73536770e-03  5.08187300e-01]\n",
      "0.3571475926800008\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression using Normal Equations\n",
    "We perform a cross-validation for chosing the optimal lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "#degree = 5\n",
    "k_fold = 4\n",
    "lambdas = np.logspace(-4, 0, 30)\n",
    "\n",
    "# splitting data in k fold\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "        lambda_ = lambdas[i]\n",
    "        tr_loss = 0\n",
    "        te_loss = 0\n",
    "        for k in range(k_fold): \n",
    "            loss_tr, loss_te = cross_validation(y, tX, k_indices, k, lambda_)[1:]\n",
    "            tr_loss = tr_loss + loss_tr\n",
    "            te_loss = te_loss + loss_te\n",
    "        rmse_tr.append(np.sqrt(2 * tr_loss/k_fold))\n",
    "        rmse_te.append(np.sqrt(2 * te_loss/k_fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 62500)\n",
      "[0.8451559762683958, 0.8451614112036048, 0.8451712453828589, 0.8451887903207852, 0.8452195307897435, 0.8452721869496425, 0.845359949238615, 0.8455016589399731, 0.8457226576988703, 0.8460552278640989, 0.846538927452292, 0.8472210782083571, 0.8481564211773459, 0.8494030230264888, 0.8510115066755363, 0.8530090117407382, 0.8553860748850798, 0.8580973353290767, 0.8610808707604044, 0.8642898100449252, 0.867723077514569, 0.8714443202814338, 0.8755846042342056, 0.8803282157154915, 0.8858805947477761, 0.8924183878534053, 0.900029441431769, 0.9086629740901928, 0.9181148005746428, 0.928058088415232]\n",
      "[0.8452383894121399, 0.8452437318954308, 0.8452534425190434, 0.8452708237816218, 0.8453013497936661, 0.845353728644392, 0.8454411377574003, 0.8455824050277555, 0.8458028587465765, 0.8461347678977268, 0.8466176765467694, 0.8472988910538661, 0.8482331348804624, 0.849478454283935, 0.8510854482665314, 0.853081228467293, 0.8554562999666743, 0.858165269056161, 0.8611461828162709, 0.8643521454511774, 0.8677820651202615, 0.8714995832565531, 0.8756357738281949, 0.8803749511846741, 0.8859226120893972, 0.8924554965321925, 0.9000615822588529, 0.908690246272008, 0.9181374662628439, 0.9280765503329274]\n"
     ]
    }
   ],
   "source": [
    "print(k_indices.shape)\n",
    "#print(rmse_tr)\n",
    "#print(rmse_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
